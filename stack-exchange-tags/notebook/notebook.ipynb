{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on [this comment][1]\n",
    "\n",
    "  [1]: https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction/forums/t/6650/share-your-approach?forumMessageId=36434#post36434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display\n",
    "from six.moves import cPickle as pickle\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def maybe_pickle(file_name, load_dataset, force=False):\n",
    "    pickle_file_name = \"pickle/\" + file_name + \".pickle\"\n",
    "    import os\n",
    "    if not os.path.exists(\"pickle\"):\n",
    "        os.makedirs(\"pickle\")\n",
    "        \n",
    "    if os.path.exists(pickle_file_name) and not force:\n",
    "        # You may override by setting force=True.\n",
    "        print('%s already present - Skipping pickling.' % pickle_file_name)\n",
    "    else:\n",
    "        print('Pickling %s.' % pickle_file_name)\n",
    "        dataset = load_dataset(None)\n",
    "        try:\n",
    "            with open(pickle_file_name, 'wb') as f:\n",
    "                pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to', file_name, ':', e)\n",
    "    \n",
    "    return pickle_file_name\n",
    "\n",
    "def load_data(file_name, force=False):\n",
    "    original_file_path = \"../input/\" + file_name + \".csv\"\n",
    "    pickle_file_name = maybe_pickle(file_name, lambda x: pd.read_csv(original_file_path), force)\n",
    "    \n",
    "    with open(pickle_file_name, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle/biology.pickle already present - Skipping pickling.\n",
      "pickle/cooking.pickle already present - Skipping pickling.\n",
      "pickle/crypto.pickle already present - Skipping pickling.\n",
      "pickle/diy.pickle already present - Skipping pickling.\n",
      "pickle/robotics.pickle already present - Skipping pickling.\n",
      "pickle/travel.pickle already present - Skipping pickling.\n"
     ]
    }
   ],
   "source": [
    "biology = load_data(\"biology\")\n",
    "cooking = load_data(\"cooking\")\n",
    "crypto = load_data(\"crypto\")\n",
    "diy = load_data(\"diy\")\n",
    "robotics = load_data(\"robotics\")\n",
    "travel = load_data(\"travel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "punctuation_trans_table = str.maketrans({key: None for key in string.punctuation})\n",
    "html_tag_regex = re.compile('<.*?>')\n",
    "code_tag_regex = re.compile('<code>([^<]+)</code>', re.S)\n",
    "a_tag_regex = re.compile('<a href([^<]+)</a>', re.S)\n",
    "\n",
    "def cleaning_text(text):\n",
    "    original_text_length = len(text)\n",
    "    number_of_html_tag = len(re.findall(html_tag_regex, text))\n",
    "    number_of_code_fragments = len(re.findall(code_tag_regex, text))\n",
    "    number_of_a_href = len(re.findall(a_tag_regex, text))\n",
    "    \n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    # remove code fragment\n",
    "    text = re.sub(code_tag_regex, 'code_tag', text)\n",
    "    # remove html tags\n",
    "    text = re.sub(html_tag_regex, '', text)\n",
    "    # remove \\r, \\n\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '')\n",
    "    # remove Punctuations\n",
    "    text = text.translate(punctuation_trans_table)\n",
    "    # split\n",
    "    words = word_tokenize(text)\n",
    "    # remove stop words\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    # lemmatizing, stemming\n",
    "    words = [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    # join\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    number_of_cleaned_text_tokens = len(words)\n",
    "    cleaned_text_length = len(text)\n",
    "    return text, [original_text_length, number_of_html_tag, number_of_code_fragments, number_of_a_href, number_of_cleaned_text_tokens, cleaned_text_length]\n",
    "\n",
    "\n",
    "def cleaning(row):\n",
    "    row['title'], title_meta_list = cleaning_text(row['title'])\n",
    "    row['title_original_text_length'] = title_meta_list[0]\n",
    "    row['title_number_of_cleaned_text_tokens'] = title_meta_list[4]\n",
    "    row['title_cleaned_text_length'] = title_meta_list[5]\n",
    "    \n",
    "    row['content'], content_meta_list = cleaning_text(row['content'])\n",
    "    row['content_original_text_length'] = content_meta_list[0]\n",
    "    row['content_number_of_html_tag'] = content_meta_list[1]\n",
    "    row['content_number_of_code_fragments'] = content_meta_list[2]\n",
    "    row['content_number_of_a_href'] = content_meta_list[3]\n",
    "    row['content_number_of_cleaned_text_tokens'] = content_meta_list[4]\n",
    "    row['content_cleaned_text_length'] = content_meta_list[5]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_cleaned_df(file_name, force=False):\n",
    "    original_file_path = \"../input/\" + file_name + \".csv\"\n",
    "    df = pd.read_csv(original_file_path)\n",
    "    print(\"total len : %d\" % len(df))\n",
    "    result_df = df.progress_apply(cleaning, axis=1)\n",
    "    \n",
    "    # feature scaling for meta columns\n",
    "    result_df['title_original_text_length'] = min_max_scaler.fit_transform(result_df['title_original_text_length'])\n",
    "    result_df['title_number_of_cleaned_text_tokens'] = min_max_scaler.fit_transform(result_df['title_number_of_cleaned_text_tokens'])\n",
    "    result_df['title_cleaned_text_length'] = min_max_scaler.fit_transform(result_df['title_cleaned_text_length'])\n",
    "    result_df['content_original_text_length'] = min_max_scaler.fit_transform(result_df['content_original_text_length'])\n",
    "    result_df['content_number_of_html_tag'] = min_max_scaler.fit_transform(result_df['content_number_of_html_tag'])\n",
    "    result_df['content_number_of_code_fragments'] = min_max_scaler.fit_transform(result_df['content_number_of_code_fragments'])\n",
    "    result_df['content_number_of_a_href'] = min_max_scaler.fit_transform(result_df['content_number_of_a_href'])\n",
    "    result_df['content_number_of_cleaned_text_tokens'] = min_max_scaler.fit_transform(result_df['content_number_of_cleaned_text_tokens'])\n",
    "    result_df['content_cleaned_text_length'] = min_max_scaler.fit_transform(result_df['content_cleaned_text_length'])\n",
    "    \n",
    "    return result_df\n",
    "    \n",
    "def maybe_pickle_cleaned_df(file_name, force=False):\n",
    "    pickle_file_name = maybe_pickle(file_name + \"_cleaned\", lambda x: load_cleaned_df(file_name), force)\n",
    "    \n",
    "    with open(pickle_file_name, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle/biology_cleaned.pickle already present - Skipping pickling.\n",
      "pickle/cooking_cleaned.pickle already present - Skipping pickling.\n",
      "pickle/crypto_cleaned.pickle already present - Skipping pickling.\n",
      "pickle/diy_cleaned.pickle already present - Skipping pickling.\n",
      "pickle/robotics_cleaned.pickle already present - Skipping pickling.\n",
      "pickle/travel_cleaned.pickle already present - Skipping pickling.\n"
     ]
    }
   ],
   "source": [
    "biology_cleaned_df = maybe_pickle_cleaned_df('biology')\n",
    "cooking_cleaned_df = maybe_pickle_cleaned_df('cooking')\n",
    "crypto_cleaned_df = maybe_pickle_cleaned_df('crypto')\n",
    "diy_cleaned_df = maybe_pickle_cleaned_df('diy')\n",
    "robotics_cleaned_df = maybe_pickle_cleaned_df('robotics')\n",
    "travel_cleaned_df = maybe_pickle_cleaned_df('travel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tags count : 33129\n",
      "unique tags count : 678\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.862832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>126.580001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1448.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count\n",
       "count   678.000000\n",
       "mean     48.862832\n",
       "std     126.580001\n",
       "min       1.000000\n",
       "25%       5.000000\n",
       "50%      14.000000\n",
       "75%      38.000000\n",
       "max    1448.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>human-biology</th>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genetics</th>\n",
       "      <td>1229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evolution</th>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biochemistry</th>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>molecular-biology</th>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count\n",
       "human-biology       1448\n",
       "genetics            1229\n",
       "evolution           1159\n",
       "biochemistry         984\n",
       "molecular-biology    863"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tags count : 35542\n",
      "unique tags count : 736\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>736.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.290761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>106.684593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1444.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count\n",
       "count   736.000000\n",
       "mean     48.290761\n",
       "std     106.684593\n",
       "min       1.000000\n",
       "25%       7.000000\n",
       "50%      18.000000\n",
       "75%      43.000000\n",
       "max    1444.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baking</th>\n",
       "      <td>1444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food-safety</th>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>substitutions</th>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equipment</th>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bread</th>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count\n",
       "baking          1444\n",
       "food-safety     1211\n",
       "substitutions    920\n",
       "equipment        816\n",
       "bread            687"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tags count : 25484\n",
      "unique tags count : 392\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>65.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>156.041030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1783.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count\n",
       "count   392.000000\n",
       "mean     65.010204\n",
       "std     156.041030\n",
       "min       1.000000\n",
       "25%       6.000000\n",
       "50%      18.500000\n",
       "75%      54.000000\n",
       "max    1783.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>encryption</th>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hash</th>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rsa</th>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aes</th>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public-key</th>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count\n",
       "encryption   1783\n",
       "hash         1141\n",
       "rsa          1095\n",
       "aes           923\n",
       "public-key    842"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tags count : 59129\n",
      "unique tags count : 734\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>734.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>80.557221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>227.936610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4490.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count\n",
       "count   734.000000\n",
       "mean     80.557221\n",
       "std     227.936610\n",
       "min       1.000000\n",
       "25%       9.000000\n",
       "50%      25.000000\n",
       "75%      72.000000\n",
       "max    4490.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>electrical</th>\n",
       "      <td>4490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plumbing</th>\n",
       "      <td>2223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiring</th>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lighting</th>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hvac</th>\n",
       "      <td>922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count\n",
       "electrical   4490\n",
       "plumbing     2223\n",
       "wiring       1674\n",
       "lighting     1003\n",
       "hvac          922"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tags count : 6520\n",
      "unique tags count : 231\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>231.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.225108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>48.026908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>306.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count\n",
       "count  231.000000\n",
       "mean    28.225108\n",
       "std     48.026908\n",
       "min      1.000000\n",
       "25%      4.500000\n",
       "50%     11.000000\n",
       "75%     31.000000\n",
       "max    306.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>quadcopter</th>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile-robot</th>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arduino</th>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>control</th>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motor</th>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "quadcopter      306\n",
       "mobile-robot    295\n",
       "arduino         282\n",
       "control         255\n",
       "motor           239"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tags count : 65334\n",
      "unique tags count : 1645\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1645.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.716717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>157.570955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3829.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count\n",
       "count  1645.000000\n",
       "mean     39.716717\n",
       "std     157.570955\n",
       "min       1.000000\n",
       "25%       3.000000\n",
       "50%       7.000000\n",
       "75%      23.000000\n",
       "max    3829.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>visas</th>\n",
       "      <td>3829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air-travel</th>\n",
       "      <td>2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usa</th>\n",
       "      <td>2168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schengen</th>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count\n",
       "visas        3829\n",
       "air-travel   2273\n",
       "usa          2168\n",
       "schengen     1561\n",
       "uk           1492"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract most common tags\n",
    "def extract_tags_count(cleaned_df):\n",
    "    tags_list = cleaned_df['tags'].str.split(pat=' ').tolist()\n",
    "    total_tags = pd.Series([item for sublist in tags_list for item in sublist])\n",
    "    print(\"total tags count : %d\" % len(total_tags))\n",
    "    total_tags = pd.DataFrame(total_tags.value_counts(), columns=['count'])\n",
    "    print(\"unique tags count : %d\" % len(total_tags))\n",
    "    display(total_tags.describe())\n",
    "    display(total_tags.head())\n",
    "    return total_tags\n",
    "\n",
    "\n",
    "biology_total_tags = extract_tags_count(biology_cleaned_df)\n",
    "cooking_total_tags = extract_tags_count(cooking_cleaned_df)\n",
    "crypto_total_tags = extract_tags_count(crypto_cleaned_df)\n",
    "diy_total_tags = extract_tags_count(diy_cleaned_df)\n",
    "robotics_total_tags = extract_tags_count(robotics_cleaned_df)\n",
    "travel_total_tags = extract_tags_count(travel_cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87000\n",
      "   id                                              title  \\\n",
      "0   1  what critic ribosom bind site relat start codo...   \n",
      "1   2         how rnase contamin rna base experi prevent   \n",
      "2   3               are lymphocyt size cluster two group   \n",
      "3   4     how long antibioticdos lb maintain good select   \n",
      "4   5                 is exon order alway preserv splice   \n",
      "\n",
      "                                             content  \\\n",
      "0  in prokaryot translat critic effici translat l...   \n",
      "1  doe anyon suggest prevent rnase contamin work ...   \n",
      "2  tortora write principl anatomi physiolog lymph...   \n",
      "3  various peopl lab prepar liter lb add kanamyci...   \n",
      "4  are case splice machineri construct mrna exon ...   \n",
      "\n",
      "                                                tags category  \n",
      "0  ribosome binding-sites translation synthetic-b...  biology  \n",
      "1                                   rna biochemistry  biology  \n",
      "2                 immunology cell-biology hematology  biology  \n",
      "3                                       cell-culture  biology  \n",
      "4            splicing mrna spliceosome introns exons  biology  \n"
     ]
    }
   ],
   "source": [
    "# predict which category.\n",
    "def create_category_added_df(df, category):\n",
    "    temp_df = df.copy()\n",
    "    temp_df['category'] = category\n",
    "    return temp_df\n",
    "\n",
    "\n",
    "full_df = pd.concat([create_category_added_df(biology_cleaned_df, 'biology'),\n",
    "                    create_category_added_df(cooking_cleaned_df, 'cooking'),\n",
    "                    create_category_added_df(crypto_cleaned_df, 'crypto'),\n",
    "                    create_category_added_df(diy_cleaned_df, 'diy'),\n",
    "                    create_category_added_df(robotics_cleaned_df, 'robotics'),\n",
    "                    create_category_added_df(travel_cleaned_df, 'travel')]\n",
    "                   )\n",
    "\n",
    "print(len(full_df))\n",
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS\n",
    "full_df_vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "full_df_vectors = full_df_vectorizer.fit_transform((full_df['title'] + \" \" + full_df['content']).tolist())\n",
    "print(len(full_df_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98038314176245211"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD classifier for predict category.\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "category_classifier = SGDClassifier(loss=\"modified_huber\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(full_df_vectors, full_df['category'], test_size=0.3, random_state=42)\n",
    "category_classifier.fit(X_train, y_train)\n",
    "category_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_has_tag_columns(cleaned_df_input, total_tags_df, min_tag_apper_count, in_place=False):\n",
    "    tag_split_df = cleaned_df_input\n",
    "    if not in_place:\n",
    "        tag_split_df = cleaned_df_input.copy()\n",
    "        \n",
    "    if not 'split_tag' in tag_split_df.columns:\n",
    "        tag_split_df['split_tag'] = tag_split_df['tags'].str.split()\n",
    "        \n",
    "    tags = total_tags_df[total_tags_df['count'] >= min_tag_apper_count].index\n",
    "    print(\"start\")\n",
    "    print(\"total tags : %d\" % len(tags))\n",
    "    for tag in tags:\n",
    "        print(\"add tag : %s\" % tag)\n",
    "        tag_split_df[\"is_has_%s\" % tag] = tag_split_df.apply(lambda row: tag in row['split_tag'], axis=1)\n",
    "    print(\"finish\")\n",
    "    \n",
    "    return tag_split_df\n",
    "\n",
    "def maybe_pickle_has_tag_df(file_name, cleaned_df, total_tags_df, min_tag_apper_count, force=False):\n",
    "    pickle_file_name = maybe_pickle(file_name + \"_has_tag\", lambda x: add_has_tag_columns(cleaned_df, total_tags_df, min_tag_apper_count), force)\n",
    "    \n",
    "    with open(pickle_file_name, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle/biology_has_tag.pickle already present - Skipping pickling.\n",
      "pickle/cooking_has_tag.pickle already present - Skipping pickling.\n",
      "pickle/crypto_has_tag.pickle already present - Skipping pickling.\n",
      "pickle/diy_has_tag.pickle already present - Skipping pickling.\n",
      "pickle/robotics_has_tag.pickle already present - Skipping pickling.\n",
      "pickle/travel_has_tag.pickle already present - Skipping pickling.\n",
      "541\n",
      "627\n",
      "319\n",
      "634\n",
      "178\n",
      "1027\n"
     ]
    }
   ],
   "source": [
    "biology_has_tag_df = maybe_pickle_has_tag_df('biology', biology_cleaned_df, biology_total_tags, 5)\n",
    "cooking_has_tag_df = maybe_pickle_has_tag_df('cooking', cooking_cleaned_df, cooking_total_tags, 5)\n",
    "crypto_has_tag_df = maybe_pickle_has_tag_df('crypto', crypto_cleaned_df, crypto_total_tags, 5)\n",
    "diy_has_tag_df = maybe_pickle_has_tag_df('diy', diy_cleaned_df, diy_total_tags, 5)\n",
    "robotics_has_tag_df = maybe_pickle_has_tag_df('robotics', robotics_cleaned_df, robotics_total_tags, 5)\n",
    "travel_has_tag_df = maybe_pickle_has_tag_df('travel', travel_cleaned_df, travel_total_tags, 5)\n",
    "print(len(biology_has_tag_df.columns))\n",
    "print(len(cooking_has_tag_df.columns))\n",
    "print(len(crypto_has_tag_df.columns))\n",
    "print(len(diy_has_tag_df.columns))\n",
    "print(len(robotics_has_tag_df.columns))\n",
    "print(len(travel_has_tag_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle/biology_vectors.pickle already present - Skipping pickling.\n",
      "pickle/cooking_vectors.pickle already present - Skipping pickling.\n",
      "pickle/crypto_vectors.pickle already present - Skipping pickling.\n",
      "pickle/diy_vectors.pickle already present - Skipping pickling.\n",
      "pickle/robotics_vectors.pickle already present - Skipping pickling.\n",
      "pickle/travel_vectors.pickle already present - Skipping pickling.\n",
      "38497\n",
      "23660\n",
      "45476\n",
      "36376\n",
      "23038\n",
      "33711\n"
     ]
    }
   ],
   "source": [
    "def generate_vectors(df):\n",
    "    vectorizer = TfidfVectorizer(stop_words=text.ENGLISH_STOP_WORDS)\n",
    "    vectors = vectorizer.fit_transform((df['title'] + \" \" + df['content']).tolist())\n",
    "    return (vectorizer, vectors)\n",
    "\n",
    "\n",
    "def maybe_pickle_vectors(file_name, df, force=False):\n",
    "    pickle_file_name = maybe_pickle(file_name + \"_vectors\", lambda x: generate_vectors(df), force)\n",
    "    \n",
    "    with open(pickle_file_name, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "biology_vectorizer, biology_vectors = maybe_pickle_vectors(\"biology\", biology_cleaned_df)\n",
    "cooking_vectorizer, cooking_vectors = maybe_pickle_vectors(\"cooking\", cooking_cleaned_df)\n",
    "crypto_vectorizer, crypto_vectors = maybe_pickle_vectors(\"crypto\", crypto_cleaned_df)\n",
    "diy_vectorizer, diy_vectors = maybe_pickle_vectors(\"diy\", diy_cleaned_df)\n",
    "robotics_vectorizer, robotics_vectors = maybe_pickle_vectors(\"robotics\", robotics_cleaned_df)\n",
    "travel_vectorizer, travel_vectors = maybe_pickle_vectors(\"travel\", travel_cleaned_df)\n",
    "print(len(biology_vectorizer.get_feature_names()))\n",
    "print(len(cooking_vectorizer.get_feature_names()))\n",
    "print(len(crypto_vectorizer.get_feature_names()))\n",
    "print(len(diy_vectorizer.get_feature_names()))\n",
    "print(len(robotics_vectorizer.get_feature_names()))\n",
    "print(len(travel_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_dict = {'biology':biology_vectorizer,\n",
    "                  'cooking':cooking_vectorizer,\n",
    "                  'crypto':crypto_vectorizer,\n",
    "                  'diy':diy_vectorizer,\n",
    "                  'robotics':robotics_vectorizer,\n",
    "                  'travel':travel_vectorizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biology\n",
      "Pickling pickle/biology_classifier.pickle.\n",
      "used tag count : 536 / 678\n",
      "average accuracy : 0.995697\n",
      "cooking\n",
      "Pickling pickle/cooking_classifier.pickle.\n",
      "used tag count : 622 / 736\n",
      "average accuracy : 0.997094\n",
      "crypto\n",
      "Pickling pickle/crypto_classifier.pickle.\n",
      "used tag count : 314 / 392\n",
      "average accuracy : 0.993633\n",
      "diy\n",
      "Pickling pickle/diy_classifier.pickle.\n",
      "used tag count : 629 / 734\n",
      "average accuracy : 0.996921\n",
      "robotics\n",
      "Pickling pickle/robotics_classifier.pickle.\n",
      "used tag count : 173 / 231\n",
      "average accuracy : 0.987932\n",
      "travel\n",
      "Pickling pickle/travel_classifier.pickle.\n",
      "used tag count : 1022 / 1645\n",
      "average accuracy : 0.997430\n"
     ]
    }
   ],
   "source": [
    "def create_tag_classifier(total_tags, vectors, full_df):\n",
    "    classifier_map = {}\n",
    "    \n",
    "    total_count = 0\n",
    "    total_accuracy = 0.0\n",
    "    for tag in total_tags.index:\n",
    "        tag_column = 'is_has_%s' % tag\n",
    "        if tag_column in full_df.columns:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(vectors, \n",
    "                                                                full_df[tag_column].astype(float), \n",
    "                                                                test_size=0.3, \n",
    "                                                                random_state=42)\n",
    "            clf = SGDClassifier(loss=\"modified_huber\")\n",
    "            clf.fit(X_train, y_train)\n",
    "            total_count += 1\n",
    "            total_accuracy += clf.score(X_test, y_test)\n",
    "            classifier_map[tag] = clf\n",
    "    print(\"used tag count : %d / %d\" % (total_count, len(total_tags)))\n",
    "    print(\"average accuracy : %f\" % (total_accuracy / total_count))\n",
    "    \n",
    "    return classifier_map\n",
    "\n",
    "\n",
    "def maybe_pickle_classifier(file_name, total_tags, vectors, full_df, force=False):\n",
    "    pickle_file_name = maybe_pickle(file_name + \"_classifier\", lambda x: create_tag_classifier(total_tags, vectors, full_df), force)\n",
    "    \n",
    "    with open(pickle_file_name, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# make SGD classifier tor predict tags. train with one-vs-rest approach\n",
    "print(\"biology\") \n",
    "biology_tags_classifier_dict = maybe_pickle_classifier('biology', biology_total_tags, biology_vectors, biology_has_tag_df, True)\n",
    "print(\"cooking\")\n",
    "cooking_tags_classifier_dict = maybe_pickle_classifier('cooking', cooking_total_tags, cooking_vectors, cooking_has_tag_df, True)\n",
    "print(\"crypto\")\n",
    "crypto_tags_classifier_dict = maybe_pickle_classifier('crypto', crypto_total_tags, crypto_vectors, crypto_has_tag_df, True)\n",
    "print(\"diy\")\n",
    "diy_tags_classifier_dict = maybe_pickle_classifier('diy', diy_total_tags, diy_vectors, diy_has_tag_df, True)\n",
    "print(\"robotics\")\n",
    "robotics_tags_classifier_dict = maybe_pickle_classifier('robotics', robotics_total_tags, robotics_vectors, robotics_has_tag_df, True)\n",
    "print(\"travel\")\n",
    "travel_tags_classifier_dict = maybe_pickle_classifier('travel', travel_total_tags, travel_vectors, travel_has_tag_df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_dict = {'biology':biology_tags_classifier_dict,\n",
    "                  'cooking':cooking_tags_classifier_dict,\n",
    "                  'crypto':crypto_tags_classifier_dict,\n",
    "                  'diy':diy_tags_classifier_dict,\n",
    "                  'robotics':robotics_tags_classifier_dict,\n",
    "                  'travel':travel_tags_classifier_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling pickle/test.pickle.\n",
      "Pickling pickle/test_cleaned.pickle.\n",
      "total len : 81926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81927it [55:21, 24.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# predict for test data\n",
    "test = load_data(\"test\")\n",
    "test_cleaned_df = maybe_pickle_cleaned_df('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df_vectors = full_df_vectorizer.transform((test_cleaned_df['title'] + \" \" + test_cleaned_df['content']).tolist())\n",
    "test_category = category_classifier.predict(test_df_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diy' 'crypto' 'biology' ..., 'biology' 'biology' 'robotics']\n"
     ]
    }
   ],
   "source": [
    "print(test_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_cleaned_df['category'] = test_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                                              title  \\\n",
      "11         26                   veloc object electromagnet field   \n",
      "51        147  what use way imagin concept spin relat subatom...   \n",
      "60        186                         find angular acceler torqu   \n",
      "72        228               acceler ring aerotrim human gyroscop   \n",
      "76        239                   what properti object allow float   \n",
      "84        286               how angular veloc vector rotat arent   \n",
      "94        326                      angular momentum averag torqu   \n",
      "105       361                               symmetr twin paradox   \n",
      "137       478        is possibl project magnet field locat space   \n",
      "145       503  open problem special relat noninerti motion fl...   \n",
      "147       507                         tire speed depend friction   \n",
      "169       603          chose refer frame earth rest doesnt rotat   \n",
      "187       679                                 learn physic onlin   \n",
      "194       727      what condit fulfil path mass slide lumpi hill   \n",
      "205       782      how calcul ballist trajectori suborbit flight   \n",
      "208       791                      question moment inertia veloc   \n",
      "209       798                                constraint forc rod   \n",
      "215       822                is angular momentum truli fundament   \n",
      "216       830                what direct friction forc roll ball   \n",
      "242       931                      how sail downwind faster wind   \n",
      "251       994                         what make space real space   \n",
      "252       995  simul physic impact object made finit small el...   \n",
      "256      1018                         explan simpl harmon motion   \n",
      "263      1048                           what univers rotat whole   \n",
      "286      1126             is possibl throw object faster distanc   \n",
      "289      1135                          what differ kinemat dynam   \n",
      "290      1142                    is 2d general coeffici restitut   \n",
      "294      1157            how determin phase angl sinusoid motion   \n",
      "313      1227                                       calcul gforc   \n",
      "314      1229         is situat physic right hand rule arbitrari   \n",
      "...       ...                                                ...   \n",
      "81667  277555  a disc collid anoth ident disc inelast what ma...   \n",
      "81677  277577     how earth bring fall object veloc zero contact   \n",
      "81678  277580       pendulum spring obtain express maximum speed   \n",
      "81682  277590                   visual 3d optic ray trace system   \n",
      "81683  277592                          thermal expans pump shaft   \n",
      "81685  277603  calcul field that creat spherec symmetr charg ...   \n",
      "81696  277634           laser interferometr gravit wave detector   \n",
      "81707  277652       angl sunris sunset view surfac anyway orient   \n",
      "81724  277684                     barber pole v phasegroup veloc   \n",
      "81736  277707  how angular momentum store superfluid compon p...   \n",
      "81774  277794                                acceler speed veloc   \n",
      "81794  277835                          how write equat line forc   \n",
      "81797  277841          roller coaster displac travel angl surfac   \n",
      "81799  277845                         freeli fall bodi drag forc   \n",
      "81811  277871                            characterist wavepacket   \n",
      "81821  277902                                   need help tensor   \n",
      "81824  277911               obtain posit curv veloc v time graph   \n",
      "81835  277938  use delta function relat particl phase space n...   \n",
      "81848  277967     spheric harmon schroding equat spheric coordin   \n",
      "81855  277976        whi would connect posit termin posit termin   \n",
      "81867  277991                          n1sinx1n2sinx2 ball water   \n",
      "81890  278054                   free fall termin veloc spin rate   \n",
      "81891  278055                   comput relat veloc angular veloc   \n",
      "81894  278062                          3d map equipotenti surfac   \n",
      "81895  278064                                beat physic railgun   \n",
      "81897  278071                                formula magnus forc   \n",
      "81907  278092                     fall chimney use lagrang equat   \n",
      "81918  278116                                 vector frame refer   \n",
      "81921  278119                           kinemat projectil motion   \n",
      "81925  278126                            graviti manipul possibl   \n",
      "\n",
      "                                                 content  category  \n",
      "11     i wonder someon could provid formula would tel...  robotics  \n",
      "51     the answer question what spin relat subatom pa...  robotics  \n",
      "60     we analyz video given an appli net torqu due w...  robotics  \n",
      "72     im work graphic simul fun opensourc screensav ...  robotics  \n",
      "76     i use think shape object determin abil float b...  robotics  \n",
      "84                          doe anyon intuit explan case  robotics  \n",
      "94     refer number 6 this one im stuck so angular mo...  robotics  \n",
      "105    take follow gedankenexperi two astronaut meet ...  robotics  \n",
      "137    a magnet field strength dropsoff quick distanc...  robotics  \n",
      "145    what classic open problem special relat includ...  robotics  \n",
      "147    i old non power steer car when car stationari ...  robotics  \n",
      "169    we may choos nonrot earth refer frame ask plan...  robotics  \n",
      "187    im think follow kind educ physic onlin i maste...  robotics  \n",
      "194    suppos i hill go uneven it frictionless i want...  robotics  \n",
      "205    im tri calcul initi launch angl veloc projecti...  robotics  \n",
      "208    first i swear homework im practic problem i go...  robotics  \n",
      "209    i realli hope someon take quick look follow i ...  robotics  \n",
      "215    this may seem like slight trite question one l...  robotics  \n",
      "216    suppos solid ball horizont tabl what direct fr...  robotics  \n",
      "242    recent group set record sail windpow land vehi...  robotics  \n",
      "251    by real space i mean space physic particl move...  robotics  \n",
      "252    i want simul impact two bodi accord graviti ev...  robotics  \n",
      "256    i math grad student littl bit interest physic ...  robotics  \n",
      "263    suppos millisecond big bang cosmic egg aquir l...  robotics  \n",
      "286    is possibl throw say tenni ball 1ms1 20m abl t...  robotics  \n",
      "289    i notic author literatur sometim divid charact...  robotics  \n",
      "290    the coeffici restitut character collis one dim...  robotics  \n",
      "294    if i overdamp mechan system excit sinusoid mot...  robotics  \n",
      "313    i formula textgforc fracvomega98 v speed omega...  robotics  \n",
      "314    we use right hand rule calcul torqu that direc...  robotics  \n",
      "...                                                  ...       ...  \n",
      "81667  if disc collid inelast anoth ident disc rest v...  robotics  \n",
      "81677  how earth bring fall object veloc zero contact...  robotics  \n",
      "81678  we follow linear 2nd order differenti equat de...  robotics  \n",
      "81682  i would like use model simpl 3d object eg teap...  robotics  \n",
      "81683  to determin thermal expans pump shaft follow f...  robotics  \n",
      "81685  gausss law i tri calcul use gausss law  int ...  robotics  \n",
      "81696  i tri solv excercis now i abl find eq geodet d...  robotics  \n",
      "81707  i need understand calcul angl sunris sunset vi...  robotics  \n",
      "81724  is barber pole good real life exampl explan ph...  robotics  \n",
      "81736  i tri understand current theori pulsar glitch ...  robotics  \n",
      "81774  a car motorcycl start rest set traffic light t...  robotics  \n",
      "81794  basic i elabor much rather simpli ask question...  robotics  \n",
      "81797  a rollercoast car move 194 ft horizont rise 11...  robotics  \n",
      "81799  a paratroop weigh 80 kg jump zero veloc aeropl...  robotics  \n",
      "81811  ive learn wave packet group veloc recent quest...  robotics  \n",
      "81821  i general relat cours i pretti new tensor my p...  robotics  \n",
      "81824  i enter ap physic im struggl follow i need obt...  robotics  \n",
      "81835  i question equilibrium solut phase space usual...  robotics  \n",
      "81848  the normal angular wave function call spheric ...  robotics  \n",
      "81855  my physic text book state when posit termin on...  robotics  \n",
      "81867  dont want use calculus maxwwel equat snell law...  robotics  \n",
      "81890  how calcul vertic acceler convert spin termin ...  robotics  \n",
      "81891  consid two peopl disk radius r distanc r1 r2 c...  robotics  \n",
      "81894  one plot 3d surfac plot electr potenti map two...  robotics  \n",
      "81895  ive recent think rail gun when first learn typ...  robotics  \n",
      "81897  i research onlin magnus forc came across two d...  robotics  \n",
      "81907  there interest problem fall chimney want deter...  robotics  \n",
      "81918  my textbook state follow if frame refer transl...  robotics  \n",
      "81921  a projectil fire speed 625 m angl 53 horizont...  robotics  \n",
      "81925  i done almost research subject antigrav i hope...  robotics  \n",
      "\n",
      "[7332 rows x 4 columns]\n",
      "  (0, 22342)\t0.11594456105\n",
      "  (0, 21851)\t0.232256362832\n",
      "  (0, 21652)\t0.0462469711263\n",
      "  (0, 20567)\t0.0892180731443\n",
      "  (0, 20445)\t0.12736445265\n",
      "  (0, 19563)\t0.100826480715\n",
      "  (0, 19480)\t0.0986779481619\n",
      "  (0, 19478)\t0.117253831514\n",
      "  (0, 17100)\t0.183457424101\n",
      "  (0, 16617)\t0.116312918022\n",
      "  (0, 16564)\t0.45832989915\n",
      "  (0, 15005)\t0.112816067173\n",
      "  (0, 13932)\t0.216843238739\n",
      "  (0, 13125)\t0.0831751788683\n",
      "  (0, 12949)\t0.0656048883742\n",
      "  (0, 12754)\t0.18703674197\n",
      "  (0, 12361)\t0.171135713265\n",
      "  (0, 11419)\t0.101275036137\n",
      "  (0, 10390)\t0.216843238739\n",
      "  (0, 10005)\t0.250229053377\n",
      "  (0, 9631)\t0.303617201929\n",
      "  (0, 9300)\t0.265810073357\n",
      "  (0, 9071)\t0.125055310989\n",
      "  (0, 8668)\t0.409043055807\n",
      "  (0, 7814)\t0.120265112693\n",
      "  :\t:\n",
      "  (7331, 6700)\t0.0286206041549\n",
      "  (7331, 6362)\t0.0924009541481\n",
      "  (7331, 6343)\t0.048593294853\n",
      "  (7331, 6271)\t0.0215054673302\n",
      "  (7331, 6221)\t0.0421099280628\n",
      "  (7331, 5967)\t0.0176129198383\n",
      "  (7331, 5888)\t0.0359638767803\n",
      "  (7331, 5873)\t0.23100238537\n",
      "  (7331, 5732)\t0.0462004770741\n",
      "  (7331, 5673)\t0.0735901654309\n",
      "  (7331, 5638)\t0.0281405497965\n",
      "  (7331, 5577)\t0.0292535045121\n",
      "  (7331, 5547)\t0.0299625259289\n",
      "  (7331, 5520)\t0.0312169391628\n",
      "  (7331, 5517)\t0.0390953341802\n",
      "  (7331, 5384)\t0.0324184610451\n",
      "  (7331, 5119)\t0.0226963690766\n",
      "  (7331, 5096)\t0.0824004419271\n",
      "  (7331, 5086)\t0.0359638767803\n",
      "  (7331, 4866)\t0.0198002517408\n",
      "  (7331, 4845)\t0.0446815091872\n",
      "  (7331, 4797)\t0.019623417094\n",
      "  (7331, 4779)\t0.0924009541481\n",
      "  (7331, 4485)\t0.0562810995931\n",
      "  (7331, 4437)\t0.0503259110016\n",
      "design [ 0.  0.  0. ...,  0.  0.  1.]\n",
      "wiring [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "slam [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "embedded-systems [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "kalman-filter [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "hexapod [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "robotic-arm [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "forward-kinematics [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "rock [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "radio-control [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "matlab [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "raspberry-pi [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "balance [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "battery [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "kinect [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "inverse-kinematics [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "nxt [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "planning [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "h-bridge [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "current [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "calibration [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "jacobian [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "python [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "walk [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "c [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "theory [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "stepper-motor [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "arduino [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "sensors [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "valve [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "servomotor [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "simulator [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "rangefinder [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "algorithm [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "dh-parameters [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "motion-planning [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "stepper-driver [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "roomba [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "computer-vision [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "real-time [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "books [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "noise [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "servos [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "i2c [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "errors [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "torque [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "beginner [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "3d-model [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "probability [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "reference-request [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "linux [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "machine-learning [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "vex [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "lidar [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "ugv [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "frame [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "sonar [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "robotc [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "joint [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "accelerometer [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "digital-audio [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "multi-rotor [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "manipulator [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "legged [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "orientation [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "kinematics [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "soccer [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "wheeled-robot [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "mobile-robot [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "geometry [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "microcontroller [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "automatic [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "deduced-reckoning [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "swarm [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "programming-languages [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "rcservo [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "dynamics [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "rrt [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "odometry [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "auv [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "imu [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "particle-filter [ 0.  1.  0. ...,  0.  0.  0.]\n",
      "uav [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "differential-drive [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "force-sensor [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "irobot-create [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "esc [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "quadcopter [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "serial [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "protection [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "coverage [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "ros [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "wireless [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "circuit [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "hall-sensor [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "industrial-robot [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "mindstorms [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "platform [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "motion [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "quadrature-encoder [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "tuning [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "artificial-intelligence [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "research [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "3d-printing [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "openni [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "gps [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "walking-robot [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "humanoid [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "lithium-polymer [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "power [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "cameras [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "filter [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "sensor-fusion [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "cnc [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "line-following [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "untagged [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "software [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "motor [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "two-wheeled [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "mapping [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "brushless-motor [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "localization [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "stereo-vision [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "movement [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "ardupilot [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "wifi [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "pid [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "precise-positioning [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "ekf [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "occupancygrid [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "linear-bearing [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "electronics [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "mechanism [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "usb [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "opencv [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "communication [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "automation [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "driver [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "arm [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "simulation [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "gazebo [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "beagle-bone [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "encoding [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "manufacturing [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "gyroscope [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "reinforcement-learning [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "underwater [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "mavlink [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "rotation [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "tracks [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "laser [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "c++ [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "chassis [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "avr [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "control [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "actuator [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "force [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "first-robotics [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "logic-control [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "multi-agent [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "pose [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "gearing [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "3d-reconstruction [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "visual-servoing [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "stability [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "compass [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "visualization [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "magnetometer [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "wheel [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "interrupts [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "ultrasonic-sensors [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "navigation [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "pwm [ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "def predict_tags(test_cleand_df, category):\n",
    "    target_df = test_cleaned_df[test_cleaned_df['category'] == category]\n",
    "    print(target_df)\n",
    "    vectorizer = vectorizer_dict[category]\n",
    "    vectors = vectorizer.transform(target_df['title'] + ' ' + target_df['content'])\n",
    "    print(vectors)\n",
    "    classifier_dict_inner = classifier_dict[category]\n",
    "    \n",
    "    tag_confidence_df = pd.DataFrame()\n",
    "    for classifier_name in classifier_dict_inner:\n",
    "        classifier = classifier_dict_inner[classifier_name]\n",
    "        confidence = classifier.predict(vectors)\n",
    "        print(classifier_name, confidence)\n",
    "\n",
    "predict_tags(test_cleaned_df[:100], 'robotics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
