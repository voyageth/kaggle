{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/lystdo/beat-kkbox-benchmark-without-using-metadata-0-62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/voyageth/develop/anaconda3/envs/kaggle/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## import packages\n",
    "########################################\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, Reshape\n",
    "from keras.layers.merge import concatenate, dot\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## load the data\n",
    "########################################\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "song = pd.read_csv('./input/songs.csv')\n",
    "song_extra = pd.read_csv('./input/song_extra_info.csv')\n",
    "member = pd.read_csv('./input/members.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "msno                  object\n",
       "song_id               object\n",
       "source_system_tab     object\n",
       "source_screen_name    object\n",
       "source_type           object\n",
       "target                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     int64\n",
       "msno                  object\n",
       "song_id               object\n",
       "source_system_tab     object\n",
       "source_screen_name    object\n",
       "source_type           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_id         object\n",
       "song_length      int64\n",
       "genre_ids       object\n",
       "artist_name     object\n",
       "composer        object\n",
       "lyricist        object\n",
       "language       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_id    object\n",
       "name       object\n",
       "isrc       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_extra.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "msno                      object\n",
       "city                       int64\n",
       "bd                         int64\n",
       "gender                    object\n",
       "registered_via             int64\n",
       "registration_init_time     int64\n",
       "expiration_date            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "member.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## encoding\n",
    "########################################\n",
    "target = train.target\n",
    "id_test = test.id\n",
    "\n",
    "def encode_str(train_data, test_data):\n",
    "    data_encoder = LabelEncoder()\n",
    "    data_encoder.fit(train_data.append(test_data))\n",
    "    t_train_data = data_encoder.transform(train_data)\n",
    "    t_test_data = data_encoder.transform(test_data)\n",
    "    return t_train_data, t_test_data\n",
    "\n",
    "def generate_encoded_data(data_raw, data_test_raw):\n",
    "    data, data_test = encode_str(data_raw, data_test_raw)\n",
    "    data_cnt = int(max(data.max(), data_test.max()) + 1)\n",
    "    return data, data_test, data_cnt\n",
    "\n",
    "uid_raw = train.msno\n",
    "sid_raw = train.song_id\n",
    "\n",
    "uid_test_raw = test.msno\n",
    "sid_test_raw = test.song_id\n",
    "\n",
    "uid, uid_test = encode_str(uid_raw, uid_test_raw)\n",
    "sid, sid_test = encode_str(sid_raw, sid_test_raw)\n",
    "\n",
    "u_cnt = int(max(uid.max(), uid_test.max()) + 1)\n",
    "s_cnt = int(max(sid.max(), sid_test.max()) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## train-validation split\n",
    "########################################\n",
    "\n",
    "perm = np.random.permutation(len(train))\n",
    "trn_cnt = int(len(train) * 0.7)\n",
    "\n",
    "uid_trn = uid[perm[:trn_cnt]]\n",
    "sid_trn = sid[perm[:trn_cnt]]\n",
    "target_trn = target[perm[:trn_cnt]]\n",
    "\n",
    "uid_val = uid[perm[trn_cnt:]]\n",
    "sid_val = sid[perm[trn_cnt:]]\n",
    "target_val = target[perm[trn_cnt:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## define the model\n",
    "########################################\n",
    "\n",
    "def get_model():\n",
    "    user_embeddings = Embedding(u_cnt,\n",
    "            64,\n",
    "            embeddings_initializer=RandomUniform(minval=-0.1, maxval=0.1),\n",
    "            embeddings_regularizer=l2(1e-4),\n",
    "            input_length=1,\n",
    "            trainable=True)\n",
    "    song_embeddings = Embedding(s_cnt,\n",
    "            64,\n",
    "            embeddings_initializer=RandomUniform(minval=-0.1, maxval=0.1),\n",
    "            embeddings_regularizer=l2(1e-4),\n",
    "            input_length=1,\n",
    "            trainable=True)\n",
    "\n",
    "    uid_input = Input(shape=(1,), dtype='int32')\n",
    "    embedded_usr = user_embeddings(uid_input)\n",
    "    embedded_usr = Reshape((64,))(embedded_usr)\n",
    "\n",
    "    sid_input = Input(shape=(1,), dtype='int32')\n",
    "    embedded_song = song_embeddings(sid_input)\n",
    "    embedded_song = Reshape((64,))(embedded_song)\n",
    "\n",
    "    preds = dot([embedded_usr, embedded_song], axes=1)\n",
    "    preds = concatenate([embedded_usr, embedded_song, preds])\n",
    "    \n",
    "    preds = Dense(64, activation='relu')(preds)\n",
    "    preds = Dropout(0.5)(preds)\n",
    "    \n",
    "    preds = Dense(128, activation='relu')(preds)\n",
    "    preds = Dropout(0.5)(preds)\n",
    "    \n",
    "    preds = Dense(256, activation='relu')(preds)\n",
    "    preds = Dropout(0.5)(preds)\n",
    "    \n",
    "    preds = Dense(1, activation='sigmoid')(preds)\n",
    "\n",
    "    model = Model(inputs=[uid_input, sid_input], outputs=preds)\n",
    "    \n",
    "    opt = RMSprop(lr=1e-3)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5164192 samples, validate on 2213226 samples\n",
      "Epoch 1/100\n",
      "5164192/5164192 [==============================] - 12s 2us/step - loss: 1.9932 - acc: 0.6215 - val_loss: 0.6443 - val_acc: 0.6630\n",
      "Epoch 2/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.6352 - acc: 0.6671 - val_loss: 0.6264 - val_acc: 0.6704\n",
      "Epoch 3/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.6250 - acc: 0.6722 - val_loss: 0.6235 - val_acc: 0.6711\n",
      "Epoch 4/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.6197 - acc: 0.6776 - val_loss: 0.6176 - val_acc: 0.6772\n",
      "Epoch 5/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.6156 - acc: 0.6817 - val_loss: 0.6168 - val_acc: 0.6777\n",
      "Epoch 6/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.6126 - acc: 0.6850 - val_loss: 0.6120 - val_acc: 0.6841\n",
      "Epoch 7/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.6094 - acc: 0.6882 - val_loss: 0.6101 - val_acc: 0.6860\n",
      "Epoch 8/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.6066 - acc: 0.6911 - val_loss: 0.6078 - val_acc: 0.6890\n",
      "Epoch 9/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.6044 - acc: 0.6934 - val_loss: 0.6105 - val_acc: 0.6863\n",
      "Epoch 10/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.6022 - acc: 0.6958 - val_loss: 0.6081 - val_acc: 0.6899\n",
      "Epoch 11/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.6002 - acc: 0.6982 - val_loss: 0.6060 - val_acc: 0.6938\n",
      "Epoch 12/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.5980 - acc: 0.7015 - val_loss: 0.6058 - val_acc: 0.6953\n",
      "Epoch 13/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.5950 - acc: 0.7059 - val_loss: 0.6075 - val_acc: 0.6953\n",
      "Epoch 14/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.5903 - acc: 0.7125 - val_loss: 0.6076 - val_acc: 0.6988\n",
      "Epoch 15/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.5824 - acc: 0.7233 - val_loss: 0.6113 - val_acc: 0.6992\n",
      "Epoch 16/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.5695 - acc: 0.7392 - val_loss: 0.6222 - val_acc: 0.6992\n",
      "Epoch 17/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.5512 - acc: 0.7598 - val_loss: 0.6418 - val_acc: 0.6940\n",
      "Epoch 18/100\n",
      "5164192/5164192 [==============================] - 10s 2us/step - loss: 0.5299 - acc: 0.7818 - val_loss: 0.6626 - val_acc: 0.6889\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## train the model\n",
    "########################################\n",
    "   \n",
    "model = get_model()\n",
    "early_stopping =EarlyStopping(monitor='val_acc', patience=3)\n",
    "model_path = 'bst_model.h5'\n",
    "model_checkpoint = ModelCheckpoint(model_path, save_best_only=True, \\\n",
    "        save_weights_only=True)\n",
    "\n",
    "hist = model.fit([uid_trn, sid_trn], target_trn, validation_data=([uid_val, sid_val], \\\n",
    "        target_val), epochs=100, batch_size=32768, shuffle=True, \\\n",
    "        callbacks=[early_stopping, model_checkpoint])\n",
    "model.load_weights(model_path)\n",
    "\n",
    "preds_val = model.predict([uid_val, sid_val], batch_size=32768)\n",
    "val_auc = roc_auc_score(target_val, preds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2556790/2556790 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## make the submission\n",
    "########################################\n",
    "\n",
    "preds_test = model.predict([uid_test, sid_test], batch_size=32768, verbose=1)\n",
    "sub = pd.DataFrame({'id': id_test, 'target': preds_test.ravel()})\n",
    "sub.to_csv('./keras/sub_%.5f.csv'%(val_auc), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
